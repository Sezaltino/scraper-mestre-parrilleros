# üî• Scraper Mestre Parrillero - Vers√£o Completa

Scraper completo para extrair **TODOS** os produtos do site [Loja Mestre Parrillero](https://www.lojamestreparrillero.com.br/) com pagina√ß√£o autom√°tica, m√∫ltiplas categorias e integra√ß√£o com PostgreSQL.

## ‚ú® Funcionalidades

- ‚úÖ **Pagina√ß√£o autom√°tica**: Detecta e extrai produtos de todas as p√°ginas
- ‚úÖ **7 categorias completas**: Coleta de todas as categorias do site
- ‚úÖ **100+ produtos**: Extra√ß√£o de todos os produtos dispon√≠veis
- ‚úÖ **Integra√ß√£o PostgreSQL**: Salvamento autom√°tico com deduplica√ß√£o
- ‚úÖ **Limpeza de dados**: Pre√ßos normalizados e valores num√©ricos
- ‚úÖ **Retry logic**: Retentar automaticamente em caso de erro
- ‚úÖ **Backup JSON**: Salva tamb√©m em arquivo local
- ‚úÖ **Compat√≠vel com n8n**: Output formatado para automa√ß√£o

## üìã Categorias Coletadas

1. Churrasqueiras e Parrillas
2. Bancada de Embutir
3. Churrasqueiras para Alvenaria
4. Bancada
5. Port√°til Externa
6. Sem Fuma√ßa
7. Acess√≥rios

## üöÄ Instala√ß√£o

### 1. Clonar ou baixar o projeto

```bash
cd scraper-mestre-parrillero
```

### 2. Instalar depend√™ncias

```bash
pip install -r requirements.txt
```

### 3. Instalar navegadores do Playwright

```bash
playwright install chromium
```

### 4. Configurar banco de dados (opcional)

Copie o arquivo `.env.example` para `.env` e configure suas credenciais:

```bash
cp .env.example .env
```

Edite o arquivo `.env`:

```env
DB_HOST=localhost
DB_PORT=5432
DB_NAME=mestre_parrillero
DB_USER=postgres
DB_PASSWORD=sua_senha
```

### 5. Criar banco de dados PostgreSQL

```sql
CREATE DATABASE mestre_parrillero;
```

A tabela `produtos` ser√° criada automaticamente na primeira execu√ß√£o.

## üìä Schema da Tabela PostgreSQL

```sql
CREATE TABLE produtos (
    id SERIAL PRIMARY KEY,
    produto_id VARCHAR(100),
    sku VARCHAR(100),
    nome VARCHAR(500) NOT NULL,
    preco_texto VARCHAR(50),
    preco_valor DECIMAL(10, 2),
    imagem TEXT,
    link TEXT NOT NULL UNIQUE,
    categoria VARCHAR(200),
    status VARCHAR(50),
    fonte TEXT,
    data_scraping TIMESTAMP,
    criado_em TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    atualizado_em TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**Deduplica√ß√£o**: Produtos s√£o identificados pelo `link` (URL). Se o produto j√° existir, ele ser√° atualizado.

## üéØ Como Usar

### Execu√ß√£o simples

```bash
python scraper.py
```

### Modo headless (sem interface)

Por padr√£o, o scraper roda em modo headless. Para ver o navegador funcionando, responda "s" quando perguntado.

### Output

O scraper gera:

1. **`produtos_parrilla.json`**: Backup local com todos os produtos
2. **Banco PostgreSQL**: Produtos salvos com deduplica√ß√£o
3. **Output n8n**: JSON formatado entre `__N8N_OUTPUT_START__` e `__N8N_OUTPUT_END__`

## üì¶ Estrutura dos Dados

Cada produto cont√©m:

```json
{
  "id": "123",
  "sku": "MP-001",
  "nome": "Churrasqueira Port√°til",
  "preco_texto": "R$ 1.510,40",
  "preco_valor": 1510.40,
  "imagem": "https://...",
  "link": "https://...",
  "categoria": "Churrasqueiras e Parrillas",
  "status": "Dispon√≠vel",
  "fonte": "https://...",
  "data_scraping": "2025-01-27T10:30:00"
}
```

## üîß Configura√ß√µes Avan√ßadas

### Vari√°veis de ambiente

Voc√™ pode configurar via `.env` ou vari√°veis de ambiente:

- `DB_HOST`: Host do PostgreSQL (padr√£o: localhost)
- `DB_PORT`: Porta do PostgreSQL (padr√£o: 5432)
- `DB_NAME`: Nome do banco (padr√£o: mestre_parrillero)
- `DB_USER`: Usu√°rio do banco (padr√£o: postgres)
- `DB_PASSWORD`: Senha do banco (padr√£o: postgres)

### Ajustes no c√≥digo

No arquivo `scraper.py`, voc√™ pode modificar:

```python
DEBUG = True  # Logs detalhados
MAX_RETRIES = 3  # N√∫mero de tentativas
TIMEOUT = 30000  # Timeout em milissegundos
```

### Selecionar categorias espec√≠ficas

Para coletar apenas algumas categorias, edite a lista `CATEGORIAS` no arquivo `scraper.py`.

## üîÑ Integra√ß√£o com n8n

### 1. Criar Node "Execute Command"

No n8n, adicione um node "Execute Command" com:

```bash
cd /caminho/para/scraper-mestre-parrillero && python scraper.py
```

### 2. Processar output

O JSON ser√° retornado entre os marcadores:
- `__N8N_OUTPUT_START__`
- `__N8N_OUTPUT_END__`

Use um node "Code" para extrair:

```javascript
const output = $input.first().json.stdout;
const match = output.match(/__N8N_OUTPUT_START__([\s\S]*?)__N8N_OUTPUT_END__/);
if (match) {
  const data = JSON.parse(match[1]);
  return [{ json: data }];
}
```

### 3. Agendar execu√ß√£o

Configure um node "Schedule Trigger" para executar periodicamente (ex: diariamente).

## üìà Monitoramento

O scraper fornece logs detalhados:

```
[2025-01-27 10:30:00] [INFO] üî• Iniciando scraping COMPLETO...
[2025-01-27 10:30:05] [INFO] üìÇ CATEGORIA 1/7: Churrasqueiras e Parrillas
[2025-01-27 10:30:10] [INFO] ‚úÖ Extra√≠dos 30 produtos da p√°gina 1
[2025-01-27 10:30:15] [INFO] ‚úÖ Extra√≠dos 28 produtos da p√°gina 2
[2025-01-27 10:30:20] [SUCCESS] ‚úÖ Categoria conclu√≠da: 58 produtos
...
[2025-01-27 10:35:00] [SUCCESS] üìä RESUMO FINAL
[2025-01-27 10:35:00] [SUCCESS] ‚úÖ Total de produtos: 125
```

## üêõ Troubleshooting

### Erro: "psycopg2 n√£o instalado"

```bash
pip install psycopg2-binary
```

### Erro: "Conex√£o ao PostgreSQL falhou"

Verifique:
1. PostgreSQL est√° rodando
2. Credenciais no `.env` est√£o corretas
3. Banco de dados foi criado

### Erro: "Nenhum produto encontrado"

Verifique:
1. Site est√° acess√≠vel
2. Navegador Playwright foi instalado: `playwright install chromium`
3. Tente rodar com `DEBUG = True` e veja os screenshots gerados

### Produtos duplicados

O sistema usa o campo `link` (URL) como chave √∫nica. Produtos com o mesmo link ser√£o atualizados, n√£o duplicados.

## üìù Licen√ßa

Projeto de uso pessoal para automa√ß√£o de cat√°logo de produtos.

## ü§ù Suporte

Para d√∫vidas ou problemas, verifique:
1. Logs do scraper (modo DEBUG)
2. Screenshots gerados em caso de erro
3. Arquivo `debug_page.html` (gerado em caso de falha)

## üîÆ Pr√≥ximas melhorias poss√≠veis

- [ ] Extra√ß√£o de descri√ß√£o completa dos produtos
- [ ] Captura de especifica√ß√µes t√©cnicas
- [ ] Monitoramento de mudan√ßas de pre√ßo
- [ ] Alertas por email/webhook
- [ ] API REST para consulta dos produtos
- [ ] Dashboard de visualiza√ß√£o

---

**Vers√£o**: 2.0 (Completa)
**Data**: 27/01/2025
**Autor**: Gabriel Sezaltino
